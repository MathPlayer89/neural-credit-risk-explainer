{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1d1500b1-d29e-46b2-b183-0dd23e63f6a4",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a7c2b118-da6f-40fc-93e9-44db0302dff9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Basics\n",
    "import pandas as pd  # for data manipulation and analysis\n",
    "import numpy as np   # for numerical operations\n",
    "\n",
    "# Sklearn\n",
    "from sklearn.pipeline import Pipeline # for building preprocessing pipelines\n",
    "from sklearn.impute import SimpleImputer # for imputing missing values\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder # for feature scaling and encoding\n",
    "from sklearn.model_selection import train_test_split # for splitting data into training and validation sets\n",
    "from sklearn.compose import ColumnTransformer # for applying different pipelines to different columns\n",
    "\n",
    "# Other\n",
    "import joblib # for saving our final preprocessor object\n",
    "import os # to get working directory"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce5f591e-f871-4397-be17-fea0880422eb",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "# Load Data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03a20bfe-136e-41f9-8555-90fee03f539c",
   "metadata": {},
   "source": [
    "First thing is to load in the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "995ce695-10c2-4117-a266-0ddea1e4e681",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the file path to the training data for clarity and easy modification\n",
    "file_path = \"C:/Users/barbe/OneDrive/URI DS Program/566 Advanced Topics in Machine Learning/Project/neural-credit-risk-explainer/data/train.csv\"\n",
    "\n",
    "# Load the training dataset from the specified path into a pandas DataFrame\n",
    "df_train = pd.read_csv(file_path, low_memory=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77306e4c-dae6-46c2-ae62-ecd6612d07ad",
   "metadata": {},
   "source": [
    "We set `low_memory=False` since a column was found to have mixed types.\n",
    "- This tells pandas to read the file in chunks and infer types more accurately\n",
    "- This usually resolves the warning without changing anything else."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "069897e9-0cb4-4366-ad8d-bca3c417fdea",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "# Initial Inspection"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8983b962-213c-433c-b40c-e62822c571cf",
   "metadata": {},
   "source": [
    "Next, we do our initial inspection of the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7aebac6e-a127-4132-9c9a-88da2d99212b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>Customer_ID</th>\n",
       "      <th>Month</th>\n",
       "      <th>Name</th>\n",
       "      <th>Age</th>\n",
       "      <th>SSN</th>\n",
       "      <th>Occupation</th>\n",
       "      <th>Annual_Income</th>\n",
       "      <th>Monthly_Inhand_Salary</th>\n",
       "      <th>Num_Bank_Accounts</th>\n",
       "      <th>...</th>\n",
       "      <th>Credit_Mix</th>\n",
       "      <th>Outstanding_Debt</th>\n",
       "      <th>Credit_Utilization_Ratio</th>\n",
       "      <th>Credit_History_Age</th>\n",
       "      <th>Payment_of_Min_Amount</th>\n",
       "      <th>Total_EMI_per_month</th>\n",
       "      <th>Amount_invested_monthly</th>\n",
       "      <th>Payment_Behaviour</th>\n",
       "      <th>Monthly_Balance</th>\n",
       "      <th>Credit_Score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0x1602</td>\n",
       "      <td>CUS_0xd40</td>\n",
       "      <td>January</td>\n",
       "      <td>Aaron Maashoh</td>\n",
       "      <td>23</td>\n",
       "      <td>821-00-0265</td>\n",
       "      <td>Scientist</td>\n",
       "      <td>19114.12</td>\n",
       "      <td>1824.843333</td>\n",
       "      <td>3</td>\n",
       "      <td>...</td>\n",
       "      <td>_</td>\n",
       "      <td>809.98</td>\n",
       "      <td>26.822620</td>\n",
       "      <td>22 Years and 1 Months</td>\n",
       "      <td>No</td>\n",
       "      <td>49.574949</td>\n",
       "      <td>80.41529543900253</td>\n",
       "      <td>High_spent_Small_value_payments</td>\n",
       "      <td>312.49408867943663</td>\n",
       "      <td>Good</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0x1603</td>\n",
       "      <td>CUS_0xd40</td>\n",
       "      <td>February</td>\n",
       "      <td>Aaron Maashoh</td>\n",
       "      <td>23</td>\n",
       "      <td>821-00-0265</td>\n",
       "      <td>Scientist</td>\n",
       "      <td>19114.12</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3</td>\n",
       "      <td>...</td>\n",
       "      <td>Good</td>\n",
       "      <td>809.98</td>\n",
       "      <td>31.944960</td>\n",
       "      <td>NaN</td>\n",
       "      <td>No</td>\n",
       "      <td>49.574949</td>\n",
       "      <td>118.28022162236736</td>\n",
       "      <td>Low_spent_Large_value_payments</td>\n",
       "      <td>284.62916249607184</td>\n",
       "      <td>Good</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0x1604</td>\n",
       "      <td>CUS_0xd40</td>\n",
       "      <td>March</td>\n",
       "      <td>Aaron Maashoh</td>\n",
       "      <td>-500</td>\n",
       "      <td>821-00-0265</td>\n",
       "      <td>Scientist</td>\n",
       "      <td>19114.12</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3</td>\n",
       "      <td>...</td>\n",
       "      <td>Good</td>\n",
       "      <td>809.98</td>\n",
       "      <td>28.609352</td>\n",
       "      <td>22 Years and 3 Months</td>\n",
       "      <td>No</td>\n",
       "      <td>49.574949</td>\n",
       "      <td>81.699521264648</td>\n",
       "      <td>Low_spent_Medium_value_payments</td>\n",
       "      <td>331.2098628537912</td>\n",
       "      <td>Good</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0x1605</td>\n",
       "      <td>CUS_0xd40</td>\n",
       "      <td>April</td>\n",
       "      <td>Aaron Maashoh</td>\n",
       "      <td>23</td>\n",
       "      <td>821-00-0265</td>\n",
       "      <td>Scientist</td>\n",
       "      <td>19114.12</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3</td>\n",
       "      <td>...</td>\n",
       "      <td>Good</td>\n",
       "      <td>809.98</td>\n",
       "      <td>31.377862</td>\n",
       "      <td>22 Years and 4 Months</td>\n",
       "      <td>No</td>\n",
       "      <td>49.574949</td>\n",
       "      <td>199.4580743910713</td>\n",
       "      <td>Low_spent_Small_value_payments</td>\n",
       "      <td>223.45130972736786</td>\n",
       "      <td>Good</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0x1606</td>\n",
       "      <td>CUS_0xd40</td>\n",
       "      <td>May</td>\n",
       "      <td>Aaron Maashoh</td>\n",
       "      <td>23</td>\n",
       "      <td>821-00-0265</td>\n",
       "      <td>Scientist</td>\n",
       "      <td>19114.12</td>\n",
       "      <td>1824.843333</td>\n",
       "      <td>3</td>\n",
       "      <td>...</td>\n",
       "      <td>Good</td>\n",
       "      <td>809.98</td>\n",
       "      <td>24.797347</td>\n",
       "      <td>22 Years and 5 Months</td>\n",
       "      <td>No</td>\n",
       "      <td>49.574949</td>\n",
       "      <td>41.420153086217326</td>\n",
       "      <td>High_spent_Medium_value_payments</td>\n",
       "      <td>341.48923103222177</td>\n",
       "      <td>Good</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 28 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       ID Customer_ID     Month           Name   Age          SSN Occupation  \\\n",
       "0  0x1602   CUS_0xd40   January  Aaron Maashoh    23  821-00-0265  Scientist   \n",
       "1  0x1603   CUS_0xd40  February  Aaron Maashoh    23  821-00-0265  Scientist   \n",
       "2  0x1604   CUS_0xd40     March  Aaron Maashoh  -500  821-00-0265  Scientist   \n",
       "3  0x1605   CUS_0xd40     April  Aaron Maashoh    23  821-00-0265  Scientist   \n",
       "4  0x1606   CUS_0xd40       May  Aaron Maashoh    23  821-00-0265  Scientist   \n",
       "\n",
       "  Annual_Income  Monthly_Inhand_Salary  Num_Bank_Accounts  ...  Credit_Mix  \\\n",
       "0      19114.12            1824.843333                  3  ...           _   \n",
       "1      19114.12                    NaN                  3  ...        Good   \n",
       "2      19114.12                    NaN                  3  ...        Good   \n",
       "3      19114.12                    NaN                  3  ...        Good   \n",
       "4      19114.12            1824.843333                  3  ...        Good   \n",
       "\n",
       "   Outstanding_Debt Credit_Utilization_Ratio     Credit_History_Age  \\\n",
       "0            809.98                26.822620  22 Years and 1 Months   \n",
       "1            809.98                31.944960                    NaN   \n",
       "2            809.98                28.609352  22 Years and 3 Months   \n",
       "3            809.98                31.377862  22 Years and 4 Months   \n",
       "4            809.98                24.797347  22 Years and 5 Months   \n",
       "\n",
       "   Payment_of_Min_Amount Total_EMI_per_month Amount_invested_monthly  \\\n",
       "0                     No           49.574949       80.41529543900253   \n",
       "1                     No           49.574949      118.28022162236736   \n",
       "2                     No           49.574949         81.699521264648   \n",
       "3                     No           49.574949       199.4580743910713   \n",
       "4                     No           49.574949      41.420153086217326   \n",
       "\n",
       "                  Payment_Behaviour     Monthly_Balance Credit_Score  \n",
       "0   High_spent_Small_value_payments  312.49408867943663         Good  \n",
       "1    Low_spent_Large_value_payments  284.62916249607184         Good  \n",
       "2   Low_spent_Medium_value_payments   331.2098628537912         Good  \n",
       "3    Low_spent_Small_value_payments  223.45130972736786         Good  \n",
       "4  High_spent_Medium_value_payments  341.48923103222177         Good  \n",
       "\n",
       "[5 rows x 28 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train.head()  # display the first 5 rows of the dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54b39cde-5afc-4c5b-9ffa-8867163ba367",
   "metadata": {},
   "source": [
    "Note:\n",
    "- ID, Customer_ID, and Name are unique identifiers or personal information, which isn't useful for modeling. These will likely be dropped in the cleaning step. Similarly for SSN.\n",
    "- We can see that one row has -500 for age, which clearly can't be. We'll need to clean this column and possiblt filter out extreme values.\n",
    "- Some rows are shown to have missing values. Well inspect this more and determine a course of action.\n",
    "- Credit_Mix has a values of `_`, which could be an error.\n",
    "- Payment_of_Min_Amount is \"Yes\"/\"No\" — perfect for binary encoding.\n",
    "- Payment_Behaviour has long string patterns — may be too granular for a baseline model.\n",
    "\n",
    "Next, we'll use the .info() method to get a technical summary of the dataset. This is crucial for understanding the data types of each column, identifying the number of non-null entries, and seeing the memory usage. It gives us a roadmap for which columns need type conversion or have missing data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0e739200-5422-43c4-8111-be8a2bdc233a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 100000 entries, 0 to 99999\n",
      "Data columns (total 28 columns):\n",
      " #   Column                    Non-Null Count   Dtype  \n",
      "---  ------                    --------------   -----  \n",
      " 0   ID                        100000 non-null  object \n",
      " 1   Customer_ID               100000 non-null  object \n",
      " 2   Month                     100000 non-null  object \n",
      " 3   Name                      90015 non-null   object \n",
      " 4   Age                       100000 non-null  object \n",
      " 5   SSN                       100000 non-null  object \n",
      " 6   Occupation                100000 non-null  object \n",
      " 7   Annual_Income             100000 non-null  object \n",
      " 8   Monthly_Inhand_Salary     84998 non-null   float64\n",
      " 9   Num_Bank_Accounts         100000 non-null  int64  \n",
      " 10  Num_Credit_Card           100000 non-null  int64  \n",
      " 11  Interest_Rate             100000 non-null  int64  \n",
      " 12  Num_of_Loan               100000 non-null  object \n",
      " 13  Type_of_Loan              88592 non-null   object \n",
      " 14  Delay_from_due_date       100000 non-null  int64  \n",
      " 15  Num_of_Delayed_Payment    92998 non-null   object \n",
      " 16  Changed_Credit_Limit      100000 non-null  object \n",
      " 17  Num_Credit_Inquiries      98035 non-null   float64\n",
      " 18  Credit_Mix                100000 non-null  object \n",
      " 19  Outstanding_Debt          100000 non-null  object \n",
      " 20  Credit_Utilization_Ratio  100000 non-null  float64\n",
      " 21  Credit_History_Age        90970 non-null   object \n",
      " 22  Payment_of_Min_Amount     100000 non-null  object \n",
      " 23  Total_EMI_per_month       100000 non-null  float64\n",
      " 24  Amount_invested_monthly   95521 non-null   object \n",
      " 25  Payment_Behaviour         100000 non-null  object \n",
      " 26  Monthly_Balance           98800 non-null   object \n",
      " 27  Credit_Score              100000 non-null  object \n",
      "dtypes: float64(4), int64(4), object(20)\n",
      "memory usage: 21.4+ MB\n"
     ]
    }
   ],
   "source": [
    "df_train.info()  # shows column names, non-null counts, and data types"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25ea231a-d635-4558-8cfc-5334e98d00e8",
   "metadata": {},
   "source": [
    "Note:\n",
    "- The output shows we have 100,000 entries and 28 columns.\n",
    "- We have 28 columns comprised of object, int64, and float64 dtypes.\n",
    "- 20 variables are objects, though many look like they should be numeric (Age, Annual_Income, etc). This confirms they will need to be converted.\n",
    "- We can also see that several columns have fewer than 100,000 non-null entries, indicating the presence of missing values that we must handle.\n",
    "\n",
    "We'll need to convert object-type accordingly. Missing values can be imputed or dropped. Categorical variables will need to be encoded."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "70b793a7-a416-40bf-a28b-ba5bf9716b9a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Monthly_Inhand_Salary</th>\n",
       "      <th>Num_Bank_Accounts</th>\n",
       "      <th>Num_Credit_Card</th>\n",
       "      <th>Interest_Rate</th>\n",
       "      <th>Delay_from_due_date</th>\n",
       "      <th>Num_Credit_Inquiries</th>\n",
       "      <th>Credit_Utilization_Ratio</th>\n",
       "      <th>Total_EMI_per_month</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>84998.000000</td>\n",
       "      <td>100000.000000</td>\n",
       "      <td>100000.00000</td>\n",
       "      <td>100000.000000</td>\n",
       "      <td>100000.000000</td>\n",
       "      <td>98035.000000</td>\n",
       "      <td>100000.000000</td>\n",
       "      <td>100000.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>4194.170850</td>\n",
       "      <td>17.091280</td>\n",
       "      <td>22.47443</td>\n",
       "      <td>72.466040</td>\n",
       "      <td>21.068780</td>\n",
       "      <td>27.754251</td>\n",
       "      <td>32.285173</td>\n",
       "      <td>1403.118217</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>3183.686167</td>\n",
       "      <td>117.404834</td>\n",
       "      <td>129.05741</td>\n",
       "      <td>466.422621</td>\n",
       "      <td>14.860104</td>\n",
       "      <td>193.177339</td>\n",
       "      <td>5.116875</td>\n",
       "      <td>8306.041270</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>303.645417</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-5.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>20.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>1625.568229</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>4.00000</td>\n",
       "      <td>8.000000</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>28.052567</td>\n",
       "      <td>30.306660</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>3093.745000</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>5.00000</td>\n",
       "      <td>13.000000</td>\n",
       "      <td>18.000000</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>32.305784</td>\n",
       "      <td>69.249473</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>5957.448333</td>\n",
       "      <td>7.000000</td>\n",
       "      <td>7.00000</td>\n",
       "      <td>20.000000</td>\n",
       "      <td>28.000000</td>\n",
       "      <td>9.000000</td>\n",
       "      <td>36.496663</td>\n",
       "      <td>161.224249</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>15204.633333</td>\n",
       "      <td>1798.000000</td>\n",
       "      <td>1499.00000</td>\n",
       "      <td>5797.000000</td>\n",
       "      <td>67.000000</td>\n",
       "      <td>2597.000000</td>\n",
       "      <td>50.000000</td>\n",
       "      <td>82331.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       Monthly_Inhand_Salary  Num_Bank_Accounts  Num_Credit_Card  \\\n",
       "count           84998.000000      100000.000000     100000.00000   \n",
       "mean             4194.170850          17.091280         22.47443   \n",
       "std              3183.686167         117.404834        129.05741   \n",
       "min               303.645417          -1.000000          0.00000   \n",
       "25%              1625.568229           3.000000          4.00000   \n",
       "50%              3093.745000           6.000000          5.00000   \n",
       "75%              5957.448333           7.000000          7.00000   \n",
       "max             15204.633333        1798.000000       1499.00000   \n",
       "\n",
       "       Interest_Rate  Delay_from_due_date  Num_Credit_Inquiries  \\\n",
       "count  100000.000000        100000.000000          98035.000000   \n",
       "mean       72.466040            21.068780             27.754251   \n",
       "std       466.422621            14.860104            193.177339   \n",
       "min         1.000000            -5.000000              0.000000   \n",
       "25%         8.000000            10.000000              3.000000   \n",
       "50%        13.000000            18.000000              6.000000   \n",
       "75%        20.000000            28.000000              9.000000   \n",
       "max      5797.000000            67.000000           2597.000000   \n",
       "\n",
       "       Credit_Utilization_Ratio  Total_EMI_per_month  \n",
       "count             100000.000000        100000.000000  \n",
       "mean                  32.285173          1403.118217  \n",
       "std                    5.116875          8306.041270  \n",
       "min                   20.000000             0.000000  \n",
       "25%                   28.052567            30.306660  \n",
       "50%                   32.305784            69.249473  \n",
       "75%                   36.496663           161.224249  \n",
       "max                   50.000000         82331.000000  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train.describe()  # summary stats"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f97e5630-10db-4cc1-b603-4a7d831c2ddc",
   "metadata": {},
   "source": [
    "The summary statistics reveal several data quality issues.\n",
    "- We see negative values in columns that should be non-negative, such as -1.0 in Num_Bank_Accounts and -5.0 in Delay_from_due_date. These will need correction or removal.\n",
    "- There are also extreme maximum values in Num_Bank_Accounts, Interest_Rate, and Num_Credit_Inquiries, suggesting outliers. We'll have to handle the outliers, either through clipping or filtering.\n",
    "- The wide range of values across different columns confirms that feature scaling will be essential for our neural network."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9d2b5401-24ce-411d-a88f-f42bbe78c3fc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>Customer_ID</th>\n",
       "      <th>Month</th>\n",
       "      <th>Name</th>\n",
       "      <th>Age</th>\n",
       "      <th>SSN</th>\n",
       "      <th>Occupation</th>\n",
       "      <th>Annual_Income</th>\n",
       "      <th>Num_of_Loan</th>\n",
       "      <th>Type_of_Loan</th>\n",
       "      <th>Num_of_Delayed_Payment</th>\n",
       "      <th>Changed_Credit_Limit</th>\n",
       "      <th>Credit_Mix</th>\n",
       "      <th>Outstanding_Debt</th>\n",
       "      <th>Credit_History_Age</th>\n",
       "      <th>Payment_of_Min_Amount</th>\n",
       "      <th>Amount_invested_monthly</th>\n",
       "      <th>Payment_Behaviour</th>\n",
       "      <th>Monthly_Balance</th>\n",
       "      <th>Credit_Score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>100000</td>\n",
       "      <td>100000</td>\n",
       "      <td>100000</td>\n",
       "      <td>90015</td>\n",
       "      <td>100000</td>\n",
       "      <td>100000</td>\n",
       "      <td>100000</td>\n",
       "      <td>100000</td>\n",
       "      <td>100000</td>\n",
       "      <td>88592</td>\n",
       "      <td>92998</td>\n",
       "      <td>100000</td>\n",
       "      <td>100000</td>\n",
       "      <td>100000</td>\n",
       "      <td>90970</td>\n",
       "      <td>100000</td>\n",
       "      <td>95521</td>\n",
       "      <td>100000</td>\n",
       "      <td>98800</td>\n",
       "      <td>100000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>unique</th>\n",
       "      <td>100000</td>\n",
       "      <td>12500</td>\n",
       "      <td>8</td>\n",
       "      <td>10139</td>\n",
       "      <td>1788</td>\n",
       "      <td>12501</td>\n",
       "      <td>16</td>\n",
       "      <td>18940</td>\n",
       "      <td>434</td>\n",
       "      <td>6260</td>\n",
       "      <td>749</td>\n",
       "      <td>4384</td>\n",
       "      <td>4</td>\n",
       "      <td>13178</td>\n",
       "      <td>404</td>\n",
       "      <td>3</td>\n",
       "      <td>91049</td>\n",
       "      <td>7</td>\n",
       "      <td>98792</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>top</th>\n",
       "      <td>0x1602</td>\n",
       "      <td>CUS_0xd40</td>\n",
       "      <td>January</td>\n",
       "      <td>Langep</td>\n",
       "      <td>38</td>\n",
       "      <td>#F%$D@*&amp;8</td>\n",
       "      <td>_______</td>\n",
       "      <td>36585.12</td>\n",
       "      <td>3</td>\n",
       "      <td>Not Specified</td>\n",
       "      <td>19</td>\n",
       "      <td>_</td>\n",
       "      <td>Standard</td>\n",
       "      <td>1360.45</td>\n",
       "      <td>15 Years and 11 Months</td>\n",
       "      <td>Yes</td>\n",
       "      <td>__10000__</td>\n",
       "      <td>Low_spent_Small_value_payments</td>\n",
       "      <td>__-333333333333333333333333333__</td>\n",
       "      <td>Standard</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>freq</th>\n",
       "      <td>1</td>\n",
       "      <td>8</td>\n",
       "      <td>12500</td>\n",
       "      <td>44</td>\n",
       "      <td>2833</td>\n",
       "      <td>5572</td>\n",
       "      <td>7062</td>\n",
       "      <td>16</td>\n",
       "      <td>14386</td>\n",
       "      <td>1408</td>\n",
       "      <td>5327</td>\n",
       "      <td>2091</td>\n",
       "      <td>36479</td>\n",
       "      <td>24</td>\n",
       "      <td>446</td>\n",
       "      <td>52326</td>\n",
       "      <td>4305</td>\n",
       "      <td>25513</td>\n",
       "      <td>9</td>\n",
       "      <td>53174</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            ID Customer_ID    Month    Name     Age        SSN Occupation  \\\n",
       "count   100000      100000   100000   90015  100000     100000     100000   \n",
       "unique  100000       12500        8   10139    1788      12501         16   \n",
       "top     0x1602   CUS_0xd40  January  Langep      38  #F%$D@*&8    _______   \n",
       "freq         1           8    12500      44    2833       5572       7062   \n",
       "\n",
       "       Annual_Income Num_of_Loan   Type_of_Loan Num_of_Delayed_Payment  \\\n",
       "count         100000      100000          88592                  92998   \n",
       "unique         18940         434           6260                    749   \n",
       "top         36585.12           3  Not Specified                     19   \n",
       "freq              16       14386           1408                   5327   \n",
       "\n",
       "       Changed_Credit_Limit Credit_Mix Outstanding_Debt  \\\n",
       "count                100000     100000           100000   \n",
       "unique                 4384          4            13178   \n",
       "top                       _   Standard          1360.45   \n",
       "freq                   2091      36479               24   \n",
       "\n",
       "            Credit_History_Age Payment_of_Min_Amount Amount_invested_monthly  \\\n",
       "count                    90970                100000                   95521   \n",
       "unique                     404                     3                   91049   \n",
       "top     15 Years and 11 Months                   Yes               __10000__   \n",
       "freq                       446                 52326                    4305   \n",
       "\n",
       "                     Payment_Behaviour                   Monthly_Balance  \\\n",
       "count                           100000                             98800   \n",
       "unique                               7                             98792   \n",
       "top     Low_spent_Small_value_payments  __-333333333333333333333333333__   \n",
       "freq                             25513                                 9   \n",
       "\n",
       "       Credit_Score  \n",
       "count        100000  \n",
       "unique            3  \n",
       "top        Standard  \n",
       "freq          53174  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train.describe(include='object')  # summary stats for non-numeric columns (unique values, top value, frequency)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6ed9218-2e08-4377-87bb-d67d6d9a47a8",
   "metadata": {},
   "source": [
    "Note:\n",
    "- Many columns have high cardinality, which makes them difficult to encode directly for a baseline model.\n",
    "- Columns like Payment_Behaviour and Type_of_Loan may be too granular or messy for a baseline model — we might drop them.\n",
    "- Credit_History_Age is a messy text format that will need special parsing. It'll likely be converted to total months.\n",
    "- The presence of placeholder values like _ in Amount_invested_monthly and _ in Credit_Mix indicates more data cleaning is required."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "58940886-c051-4d30-b688-b889b923ee72",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Credit_Score\n",
       "Standard    53174\n",
       "Poor        28998\n",
       "Good        17828\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train[\"Credit_Score\"].value_counts()  # counts of each category in the target column"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6d3bbe5-bd10-4179-9c65-097683f4e087",
   "metadata": {},
   "source": [
    "The target variable has three categories: 'Standard', 'Poor', and 'Good'. \n",
    "- For our binary classification task, we will map 'Poor' to 1 (high risk) and both 'Standard' and 'Good' to 0 (low risk).\n",
    "- The classes are somewhat imbalanced, with 'Poor' being the minority class, which is why using stratify during our data split is important."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d8056d63-bab4-4da4-8f4e-e163e2cf117f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Monthly_Inhand_Salary       15002\n",
       "Type_of_Loan                11408\n",
       "Name                         9985\n",
       "Credit_History_Age           9030\n",
       "Num_of_Delayed_Payment       7002\n",
       "Amount_invested_monthly      4479\n",
       "Num_Credit_Inquiries         1965\n",
       "Monthly_Balance              1200\n",
       "ID                              0\n",
       "Changed_Credit_Limit            0\n",
       "Payment_Behaviour               0\n",
       "Total_EMI_per_month             0\n",
       "Payment_of_Min_Amount           0\n",
       "Credit_Utilization_Ratio        0\n",
       "Outstanding_Debt                0\n",
       "Credit_Mix                      0\n",
       "Delay_from_due_date             0\n",
       "Customer_ID                     0\n",
       "Num_of_Loan                     0\n",
       "Interest_Rate                   0\n",
       "Num_Credit_Card                 0\n",
       "Num_Bank_Accounts               0\n",
       "Annual_Income                   0\n",
       "Occupation                      0\n",
       "SSN                             0\n",
       "Age                             0\n",
       "Month                           0\n",
       "Credit_Score                    0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train.isna().sum().sort_values(ascending=False)  # count missing values per column"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a650ac5-246a-4f50-b635-046d7f192c6a",
   "metadata": {},
   "source": [
    "The list confirms that Monthly_Inhand_Salary, Type_of_Loan, Name, Credit_History_Age, and Num_of_Delayed_Payment have a significant number of missing values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "67c2e91b-bfd0-40eb-970a-5c6e10528d54",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train.duplicated().sum()  # count of fully duplicated rows"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6e8c068-a79f-48a4-94aa-9107bd441707",
   "metadata": {},
   "source": [
    "No duplicates."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f8746ac-2efe-454f-b9f5-12d85814c1b4",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "# Data Cleaning and Feature Engineering"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea1197da-bba5-4c25-a9dd-74104a5acdda",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## Drop Irrelevant Columns"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eed60b3a-219f-4966-a6bd-62940b8d6326",
   "metadata": {},
   "source": [
    "Some columns don't contribute to prediction, may introduce noise, or house personal information. We'll start by removing them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f8f19131-25a1-4eb2-a4af-c1aaec853da7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a list of columns to drop for clarity and reusability\n",
    "columns_to_drop = [\n",
    "    \"Occupation\",          # High cardinality, will simplify for baseline model\n",
    "    \"ID\",                  # Unique identifier for the row, not a predictive feature\n",
    "    \"Customer_ID\",         # Unique identifier for the customer, not useful for generalization\n",
    "    \"Month\",               # Temporal label that adds noise without time-series modeling\n",
    "    \"Name\",                # Personal identifier with high cardinality, not predictive\n",
    "    \"SSN\",                 # Sensitive data, not useful for prediction\n",
    "    \"Type_of_Loan\",        # Multi-valued string, too complex to encode for a baseline model\n",
    "    \"Payment_Behaviour\"    # Descriptive strings that are hard to model without complex NLP\n",
    "]\n",
    "\n",
    "# Drop the specified columns from the DataFrame in-place\n",
    "df_train.drop(columns=columns_to_drop, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "cab5b140-6d4d-4016-a75e-edcafe831132",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Age</th>\n",
       "      <th>Annual_Income</th>\n",
       "      <th>Monthly_Inhand_Salary</th>\n",
       "      <th>Num_Bank_Accounts</th>\n",
       "      <th>Num_Credit_Card</th>\n",
       "      <th>Interest_Rate</th>\n",
       "      <th>Num_of_Loan</th>\n",
       "      <th>Delay_from_due_date</th>\n",
       "      <th>Num_of_Delayed_Payment</th>\n",
       "      <th>Changed_Credit_Limit</th>\n",
       "      <th>Num_Credit_Inquiries</th>\n",
       "      <th>Credit_Mix</th>\n",
       "      <th>Outstanding_Debt</th>\n",
       "      <th>Credit_Utilization_Ratio</th>\n",
       "      <th>Credit_History_Age</th>\n",
       "      <th>Payment_of_Min_Amount</th>\n",
       "      <th>Total_EMI_per_month</th>\n",
       "      <th>Amount_invested_monthly</th>\n",
       "      <th>Monthly_Balance</th>\n",
       "      <th>Credit_Score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>23</td>\n",
       "      <td>19114.12</td>\n",
       "      <td>1824.843333</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>7</td>\n",
       "      <td>11.27</td>\n",
       "      <td>4.0</td>\n",
       "      <td>_</td>\n",
       "      <td>809.98</td>\n",
       "      <td>26.822620</td>\n",
       "      <td>22 Years and 1 Months</td>\n",
       "      <td>No</td>\n",
       "      <td>49.574949</td>\n",
       "      <td>80.41529543900253</td>\n",
       "      <td>312.49408867943663</td>\n",
       "      <td>Good</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>23</td>\n",
       "      <td>19114.12</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>-1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>11.27</td>\n",
       "      <td>4.0</td>\n",
       "      <td>Good</td>\n",
       "      <td>809.98</td>\n",
       "      <td>31.944960</td>\n",
       "      <td>NaN</td>\n",
       "      <td>No</td>\n",
       "      <td>49.574949</td>\n",
       "      <td>118.28022162236736</td>\n",
       "      <td>284.62916249607184</td>\n",
       "      <td>Good</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-500</td>\n",
       "      <td>19114.12</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>7</td>\n",
       "      <td>_</td>\n",
       "      <td>4.0</td>\n",
       "      <td>Good</td>\n",
       "      <td>809.98</td>\n",
       "      <td>28.609352</td>\n",
       "      <td>22 Years and 3 Months</td>\n",
       "      <td>No</td>\n",
       "      <td>49.574949</td>\n",
       "      <td>81.699521264648</td>\n",
       "      <td>331.2098628537912</td>\n",
       "      <td>Good</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>23</td>\n",
       "      <td>19114.12</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>6.27</td>\n",
       "      <td>4.0</td>\n",
       "      <td>Good</td>\n",
       "      <td>809.98</td>\n",
       "      <td>31.377862</td>\n",
       "      <td>22 Years and 4 Months</td>\n",
       "      <td>No</td>\n",
       "      <td>49.574949</td>\n",
       "      <td>199.4580743910713</td>\n",
       "      <td>223.45130972736786</td>\n",
       "      <td>Good</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>23</td>\n",
       "      <td>19114.12</td>\n",
       "      <td>1824.843333</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>6</td>\n",
       "      <td>NaN</td>\n",
       "      <td>11.27</td>\n",
       "      <td>4.0</td>\n",
       "      <td>Good</td>\n",
       "      <td>809.98</td>\n",
       "      <td>24.797347</td>\n",
       "      <td>22 Years and 5 Months</td>\n",
       "      <td>No</td>\n",
       "      <td>49.574949</td>\n",
       "      <td>41.420153086217326</td>\n",
       "      <td>341.48923103222177</td>\n",
       "      <td>Good</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Age Annual_Income  Monthly_Inhand_Salary  Num_Bank_Accounts  \\\n",
       "0    23      19114.12            1824.843333                  3   \n",
       "1    23      19114.12                    NaN                  3   \n",
       "2  -500      19114.12                    NaN                  3   \n",
       "3    23      19114.12                    NaN                  3   \n",
       "4    23      19114.12            1824.843333                  3   \n",
       "\n",
       "   Num_Credit_Card  Interest_Rate Num_of_Loan  Delay_from_due_date  \\\n",
       "0                4              3           4                    3   \n",
       "1                4              3           4                   -1   \n",
       "2                4              3           4                    3   \n",
       "3                4              3           4                    5   \n",
       "4                4              3           4                    6   \n",
       "\n",
       "  Num_of_Delayed_Payment Changed_Credit_Limit  Num_Credit_Inquiries  \\\n",
       "0                      7                11.27                   4.0   \n",
       "1                    NaN                11.27                   4.0   \n",
       "2                      7                    _                   4.0   \n",
       "3                      4                 6.27                   4.0   \n",
       "4                    NaN                11.27                   4.0   \n",
       "\n",
       "  Credit_Mix Outstanding_Debt  Credit_Utilization_Ratio  \\\n",
       "0          _           809.98                 26.822620   \n",
       "1       Good           809.98                 31.944960   \n",
       "2       Good           809.98                 28.609352   \n",
       "3       Good           809.98                 31.377862   \n",
       "4       Good           809.98                 24.797347   \n",
       "\n",
       "      Credit_History_Age Payment_of_Min_Amount  Total_EMI_per_month  \\\n",
       "0  22 Years and 1 Months                    No            49.574949   \n",
       "1                    NaN                    No            49.574949   \n",
       "2  22 Years and 3 Months                    No            49.574949   \n",
       "3  22 Years and 4 Months                    No            49.574949   \n",
       "4  22 Years and 5 Months                    No            49.574949   \n",
       "\n",
       "  Amount_invested_monthly     Monthly_Balance Credit_Score  \n",
       "0       80.41529543900253  312.49408867943663         Good  \n",
       "1      118.28022162236736  284.62916249607184         Good  \n",
       "2         81.699521264648   331.2098628537912         Good  \n",
       "3       199.4580743910713  223.45130972736786         Good  \n",
       "4      41.420153086217326  341.48923103222177         Good  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f6a8d0c-7457-46a8-8559-f2e871c5095c",
   "metadata": {},
   "source": [
    "The unnecessary columns have been removed. The dataset is now leaner and more focused on the core financial attributes we want to model."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "481df2c8-2d9e-40f0-9761-d12b63a045f2",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## Handling Credit_History_Age"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e60bc113-ae5b-4976-bffa-d69fe627e95d",
   "metadata": {},
   "source": [
    "The Credit_History_Age column is stored as text (for example, \"22 Years and 1 Months\"). To use it as a feature, we must convert it into a single numerical unit, like total months. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "6c1607da-e3f6-4fcc-8d88-70b5b3ddf7f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a function to convert the age string to total months\n",
    "def convert_credit_age(age_str):\n",
    "    # Check if the input is a string before trying to split it\n",
    "    if isinstance(age_str, str):\n",
    "        # Use a try-except block to handle potential parsing errors\n",
    "        try:\n",
    "            # Split the string into parts based on spaces\n",
    "            parts = age_str.split()\n",
    "            # Extract the years value and convert to integer\n",
    "            years = int(parts[0])\n",
    "            # Extract the months value and convert to integer\n",
    "            months = int(parts[3])\n",
    "            # Calculate the total number of months\n",
    "            return (years * 12) + months\n",
    "        # If any error occurs during parsing (e.g., unexpected format)\n",
    "        except (ValueError, IndexError):\n",
    "            # Return a NumPy Not-a-Number (NaN) for invalid formats\n",
    "            return np.nan\n",
    "    # If the input is not a string (e.g., already NaN), return NaN\n",
    "    return np.nan\n",
    "\n",
    "# Apply the conversion function to the 'Credit_History_Age' column\n",
    "df_train['Credit_History_Age'] = df_train['Credit_History_Age'].apply(convert_credit_age)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4596e5b2-39e8-4917-97eb-90077b8d2844",
   "metadata": {},
   "source": [
    "The Credit_History_Age feature is now a numeric column representing the age in total months."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "969a233d-591d-4b1b-a6ed-19bcf0346d90",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## Convert Object Type Numeric Columns"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "168c24ad-80f6-4b08-b8b4-647c8409eb95",
   "metadata": {},
   "source": [
    "We'll convert columns that are stored as object but should be numeric. Using errors='coerce' will automatically turn any non-numeric text (like __ or other symbols) into NaN."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "6f3603a5-239b-40cf-9b82-27f8abc6d52d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# List of columns that should be numeric but are stored as object\n",
    "numeric_object_cols = [\n",
    "    \"Age\",                        # age in years\n",
    "    \"Annual_Income\",              # yearly income\n",
    "    \"Num_of_Loan\",                # number of loans held\n",
    "    \"Num_of_Delayed_Payment\",     # count of late payments\n",
    "    \"Changed_Credit_Limit\",       # change in credit limit\n",
    "    \"Outstanding_Debt\",           # total debt\n",
    "    \"Amount_invested_monthly\",    # monthly investment amount\n",
    "    \"Monthly_Balance\"             # leftover funds after expenses\n",
    "]\n",
    "\n",
    "# Loop through the list and convert each column to a numeric type\n",
    "for col in numeric_object_cols:\n",
    "    # pd.to_numeric converts values; errors='coerce' makes invalid entries into NaN\n",
    "    df_train[col] = pd.to_numeric(df_train[col], errors='coerce')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "613ca3fa-40e2-4eb7-9fea-09f14edcdd50",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## Clipping Outliers"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf86ef9d-b8a2-4c90-b340-3788d476f6ce",
   "metadata": {},
   "source": [
    "For columns with illogical values (e.g., a negative age), we will clip them to a reasonable range."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "2715cd68-eeaa-4590-a10e-05bed8b8759b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Clip the 'Age' column to a reasonable range (e.g., 18 to 100)\n",
    "df_train['Age'] = df_train['Age'].clip(lower=18, upper=100)\n",
    "\n",
    "# Clip 'Num_Bank_Accounts' to be non-negative\n",
    "df_train['Num_Bank_Accounts'] = df_train['Num_Bank_Accounts'].clip(lower=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4dacb2e-a5e4-41ed-ac58-6db2c5e5a16a",
   "metadata": {},
   "source": [
    "**Note on missing values**: I'm aware that the steps above, especially using errors='coerce', have created NaN (missing) values in the dataset. I'm intentionally leaving them in place for now. They will be handled systematically and safely in a later section using a scikit-learn imputation pipeline. This ensures that I don't introduce data leakage by imputing before we split our data."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b62ed68-baf3-481a-be7c-df5894f46a8f",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "# Encoding Target Variable"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a2e63a6-8af6-4be5-871e-72ab23675f3b",
   "metadata": {},
   "source": [
    "The target variable, Credit_Score, is categorical with values 'Good', 'Standard', and 'Poor'. For a binary classification model, we need to convert this into a numeric format. We will map the 'Poor' category to 1 (representing high risk) and the 'Standard' and 'Good' categories to 0 (representing low risk)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "e95a9cd4-d9e8-488e-9a7b-e7fac445f923",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Encoded target values: [0 1]\n"
     ]
    }
   ],
   "source": [
    "# Encode Credit_Score as binary classification target\n",
    "# Map 'Poor' to 1 (high risk), and 'Standard'/'Good' to 0 (low risk)\n",
    "df_train['Credit_Score'] = df_train['Credit_Score'].map(\n",
    "    lambda x: 1 if x == 'Poor' else 0\n",
    ")\n",
    "\n",
    "# Confirm encoding\n",
    "print(\"Encoded target values:\", df_train['Credit_Score'].unique())  # should show [0, 1]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6058b591-3330-41d9-903e-7d79b0471f4b",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "# Data Splitting"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "092228c4-da1c-42dd-b7e8-cfa25d60f56a",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## Feature Matrix and Target Vector"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be726030-5b52-4261-a369-74d2ad8c529c",
   "metadata": {},
   "source": [
    "Before splitting, we'll separate the dataset into a feature matrix X and target variable y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "4a07ce36-225b-4136-9d84-dc55dbc62e1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Separate features and target \n",
    "X = df_train.drop(columns=['Credit_Score'])  # all features\n",
    "y = df_train['Credit_Score']                 # binary target"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "381aaccd-c0fb-4e9a-8ed5-a8eea7403be0",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## Training and Validation Sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "fa7c6d7e-78ff-4483-bdae-c630528c7b1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the data into training (80%) and validation (20%) sets\n",
    "X_train, X_val, y_train, y_val = train_test_split(\n",
    "    X, y,             # The features and target data to split\n",
    "    test_size=0.2,    # Allocate 20% of the data to the validation set\n",
    "    random_state=42,  # For reproducibility\n",
    "    stratify=y        # Preserves proportion of target classes in both sets \n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "cc39bb35-edf3-4028-ba3e-cd53f89d9dcb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training features shape: (80000, 19)\n",
      "Validation features shape: (20000, 19)\n",
      "Training target shape: (80000,)\n",
      "Validation target shape: (20000,)\n",
      "Training target distribution:\n",
      " Credit_Score\n",
      "0    0.710025\n",
      "1    0.289975\n",
      "Name: proportion, dtype: float64\n",
      "Validation target distribution:\n",
      " Credit_Score\n",
      "0    0.71\n",
      "1    0.29\n",
      "Name: proportion, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "# Confirm the shapes of the splits\n",
    "print(\"Training features shape:\", X_train.shape)\n",
    "print(\"Validation features shape:\", X_val.shape)\n",
    "print(\"Training target shape:\", y_train.shape)\n",
    "print(\"Validation target shape:\", y_val.shape)\n",
    "print(\"Training target distribution:\\n\", y_train.value_counts(normalize=True))\n",
    "print(\"Validation target distribution:\\n\", y_val.value_counts(normalize=True))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d534609e-8ec7-48a6-85b4-1fbc9aa5b222",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "# Preprocessing Pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7ba6821-695c-49c5-8621-8b8d93993e1d",
   "metadata": {},
   "source": [
    "Using scikit-learn's Pipeline and ColumnTransformer, we will create a single object that handles all imputation, encoding, and scaling. This approach is clean, less prone to errors, and prevents data leakage by fitting only on the training data."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc774800-d6e3-4317-b5aa-8bc397c30fce",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## Identify Feature Types"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60d4cc6c-62b3-40f4-a7ad-f629f2de620a",
   "metadata": {},
   "source": [
    "First, we need to create separate lists of our numeric and categorical column names. The ColumnTransformer will use these lists to know which pipeline to apply to which columns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "34ebf170-371d-438d-8ebd-dc9cc6453862",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Numeric features identified: ['Age', 'Annual_Income', 'Monthly_Inhand_Salary', 'Num_Bank_Accounts', 'Num_Credit_Card', 'Interest_Rate', 'Num_of_Loan', 'Delay_from_due_date', 'Num_of_Delayed_Payment', 'Changed_Credit_Limit', 'Num_Credit_Inquiries', 'Outstanding_Debt', 'Credit_Utilization_Ratio', 'Credit_History_Age', 'Total_EMI_per_month', 'Amount_invested_monthly', 'Monthly_Balance']\n",
      "Categorical features identified: ['Credit_Mix', 'Payment_of_Min_Amount']\n"
     ]
    }
   ],
   "source": [
    "# Create a list of column names with numeric data types\n",
    "numeric_features = X_train.select_dtypes(include=['int64', 'float64']).columns.tolist()\n",
    "\n",
    "# Create a list of column names with the object data type\n",
    "categorical_features = X_train.select_dtypes(include=['object']).columns.tolist()\n",
    "\n",
    "# Print the lists to verify that our features have been correctly categorized\n",
    "print(\"Numeric features identified:\", numeric_features)\n",
    "print(\"Categorical features identified:\", categorical_features)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11a98747-f13a-4749-a1e1-ba466a32e338",
   "metadata": {},
   "source": [
    "Our feature names are now organized into two lists, ready to be passed to our transformer."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b893ce54-3840-46c0-817c-57f830b83e02",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## Numeric and Categorical Pipelines"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "091df08c-2c80-45a3-911b-11aa84bc8937",
   "metadata": {},
   "source": [
    "Next, we define the series of steps for each data type. We'll create one pipeline for numeric data (impute then scale) and another for categorical data (impute then one-hot encode)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "72437123-deb4-4191-9b3b-28c28891a814",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the transformation pipeline for numeric features\n",
    "numeric_transformer = Pipeline(steps=[\n",
    "    # Step 1: Impute missing values, replacing NaNs with the median of the column\n",
    "    ('imputer', SimpleImputer(strategy='median')),\n",
    "    # Step 2: Scale the features to have a mean of 0 and a standard deviation of 1\n",
    "    ('scaler', StandardScaler())\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "6261ee45-ef88-458a-b220-6e46a18b8706",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the transformation pipeline for categorical features\n",
    "categorical_transformer = Pipeline(steps=[\n",
    "    # Step 1: Impute missing values, replacing NaNs with the most frequent value (mode)\n",
    "    ('imputer', SimpleImputer(strategy='most_frequent')),\n",
    "    # Step 2: Convert categorical features into one-hot encoded columns\n",
    "    ('onehot', OneHotEncoder(handle_unknown='ignore')) # 'ignore' prevents errors if validation data has a category not in training data\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3dbcad2d-4fda-46ed-9f33-218b473ade8a",
   "metadata": {},
   "source": [
    "We have now defined two distinct mini-pipelines."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "905a9a3c-34ef-4852-9b10-36125208f686",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## Combine Pipelines"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5feeb0c3-4cb7-4592-8341-ffde4298bc7a",
   "metadata": {},
   "source": [
    "Now, we bring everything together. The ColumnTransformer applies the correct transformation pipeline to the correct columns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "ded2d9b5-4fdb-4d11-92b3-08439a150cc0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the main preprocessor object by combining the transformers\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        # Apply the numeric_transformer to all columns in the numeric_features list\n",
    "        ('num', numeric_transformer, numeric_features),\n",
    "        # Apply the categorical_transformer to all columns in the categorical_features list\n",
    "        ('cat', categorical_transformer, categorical_features)\n",
    "    ],\n",
    "    # Keep other columns (if any) instead of dropping them. We have none, but this is good practice.\n",
    "    remainder='passthrough'\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3991357d-8c3d-4ec7-a549-754e0f501741",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## Apply the Preprocessor"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa85afaf-926c-4018-9bff-cc8c07e34a9c",
   "metadata": {},
   "source": [
    "Finally, let's use our preprocessor. We will fit and transform it on the training data (X_train) and then only transform the validation data (X_val). This is the crucial step that prevents data leakage; the imputation and scaling parameters are learned only from the training data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "edcca6a0-b302-4e9e-a38d-eac055e5dcb9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed training data shape: (80000, 24)\n",
      "Processed validation data shape: (20000, 24)\n"
     ]
    }
   ],
   "source": [
    "# Fit the preprocessor on the training data and transform X_train\n",
    "X_train_processed = preprocessor.fit_transform(X_train)\n",
    "\n",
    "# Use the fitted preprocessor to transform the validation data\n",
    "X_val_processed = preprocessor.transform(X_val)\n",
    "\n",
    "# Print the shapes of the processed data to see the final result\n",
    "print(\"Processed training data shape:\", X_train_processed.shape)\n",
    "print(\"Processed validation data shape:\", X_val_processed.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d6cc2b4-46f4-46e4-a114-464c009bdbdb",
   "metadata": {},
   "source": [
    "Our data is now properly prepared. The final step is to save these processed datasets and the preprocessor object itself."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f931d5c9-9bf7-442c-a9d8-5f46da521039",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "# Exporting Preprocessed Data & Preprocessor"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "198eaabf-f012-4d8c-b2f0-f283977a82bf",
   "metadata": {},
   "source": [
    "The final step in this notebook is to save our outputs so they can be easily loaded into the next notebook for model training. We will save the processed datasets (X_train, X_val) and the target labels (y_train, y_val). Most importantly, we will save the fitted preprocessor object itself."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d69fc5e-aa0f-4cab-9f4f-018b1478f23f",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## Saving Preprocessed Datasets"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b68e5a22-7549-4800-b108-3e6f364bcd4b",
   "metadata": {},
   "source": [
    "While our preprocessor outputs NumPy arrays, it's best practice to convert them back to pandas DataFrames with meaningful column names before saving. This is especially important for this project, as it will make interpreting our model with SHAP much easier later."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "ddc763f2-389c-409a-b898-befebd8a70eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the feature names from the one-hot encoding step\n",
    "ohe_feature_names = preprocessor.named_transformers_['cat']['onehot'].get_feature_names_out(categorical_features)\n",
    "\n",
    "# Combine the original numeric feature names with the new one-hot encoded feature names\n",
    "final_feature_names = numeric_features + ohe_feature_names.tolist()\n",
    "\n",
    "# Convert the processed training data array back to a DataFrame with correct column names\n",
    "X_train_df = pd.DataFrame(X_train_processed, columns=final_feature_names, index=X_train.index)\n",
    "\n",
    "# Convert the processed validation data array back to a DataFrame with correct column names\n",
    "X_val_df = pd.DataFrame(X_val_processed, columns=final_feature_names, index=X_val.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "24c4a636-7d83-41ac-8578-b57717dc469d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the processed training features DataFrame to a CSV file\n",
    "X_train_df.to_csv(\"../data/X_train_processed.csv\", index=False)\n",
    "\n",
    "# Save the processed validation features DataFrame to a CSV file\n",
    "X_val_df.to_csv(\"../data/X_val_processed.csv\", index=False)\n",
    "\n",
    "# Save the training target Series to a CSV file\n",
    "y_train.to_csv(\"../data/y_train.csv\", index=False, header=True)\n",
    "\n",
    "# Save the validation target Series to a CSV file\n",
    "y_val.to_csv(\"../data/y_val.csv\", index=False, header=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dafbd500-136b-424e-8262-56879e706fe1",
   "metadata": {},
   "source": [
    "Our fully processed training and validation datasets are now saved as CSV files. The next notebook can load these directly to begin model training without needing to re-run any of these preprocessing steps."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4f53944-5f64-4f6a-baba-423e18617496",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## Saving Preprocessing Pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ace86a65-6cbe-4bf0-81ad-a648de538ca9",
   "metadata": {},
   "source": [
    "We save the preprocessor object, which has been fitted on our training data. This single file contains all the necessary information (medians for imputation, scales, one-hot encoding mappings) to process new, unseen data—like the official test.csv—in exactly the same way."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "a76424cb-8495-4e95-b68e-4107af533af1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['../models/preprocessor.pkl']"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Define the file path for saving the preprocessor object (in a 'models' folder)\n",
    "preprocessor_path = \"../models/preprocessor.pkl\"\n",
    "\n",
    "# Use joblib to serialize and save the fitted preprocessor object to a binary file\n",
    "joblib.dump(preprocessor, preprocessor_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38a44a0d-4363-4814-bc9c-97dc1dddc9fb",
   "metadata": {},
   "source": [
    "Our preprocessor is now saved. This concludes the data preprocessing notebook. We have successfully cleaned the data, engineered features, and created a robust, reusable pipeline to prepare the data for modeling."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "d393bb68-b9c8-4430-821b-7439a73dbad8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:\\Users\\barbe\\OneDrive\\URI DS Program\\566 Advanced Topics in Machine Learning\\Project\\neural-credit-risk-explainer\\notebooks\n"
     ]
    }
   ],
   "source": [
    "# Get working directory to see where all this is saved\n",
    "print(os.getcwd())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "972ecdd6-e7a3-47c6-a2a4-d9cb2cf85d10",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
